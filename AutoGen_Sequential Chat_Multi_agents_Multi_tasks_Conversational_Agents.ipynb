{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10edb134",
   "metadata": {},
   "source": [
    "With conversational agents we can split a process and define various agents for each task in the process and then ask to each agent to do separate task and finally we get the final results.\n",
    "See this example: we split the task into subtasks and defined amy agents and then each agent has done them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c02bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in c:\\users\\moham\\anaconda3\\lib\\site-packages (0.2.33)\n",
      "Requirement already satisfied: diskcache in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (7.1.0)\n",
      "Requirement already satisfied: flaml in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (1.35.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (23.2)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (2.5.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (1.0.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (2.4.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (0.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.14.5)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from docker->pyautogen) (306)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from docker->pyautogen) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from docker->pyautogen) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tiktoken->pyautogen) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.26.0->docker->pyautogen) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.3->pyautogen) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ef07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openAI_API_Key=os.environ['openAI_API_Key']\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce26fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2081b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6432dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding Personal Information Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's name and location.\n",
    "    Do not ask for other information. Return 'TERMINATE' \n",
    "    when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111fd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"Onboarding Topic preference Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    Do not ask for other information.\n",
    "    Return 'TERMINATE' when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0a563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer Engagement Agent\",\n",
    "    system_message='''You are a helpful customer service agent\n",
    "    here to provide fun for the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05ad0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476dc45",
   "metadata": {},
   "source": [
    "Now, you can craft a series of tasks to facilitate the onboarding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9180b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you get started with our product.\"\n",
    "            \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into as JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\" : True\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "                \"Great! Could you tell me what topics you are \"\n",
    "                \"interested in reading about?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\" : False\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56857378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************************\n",
      "Starting a new chat....\n",
      "\n",
      "********************************************************************************\n",
      "Onboarding Personal Information Agent (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\autogen\\agentchat\\chat.py:47: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to Onboarding Personal Information Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: Ali from Montreal\n",
      "customer_proxy_agent (to Onboarding Personal Information Agent):\n",
      "\n",
      "Ali from Montreal\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Onboarding Personal Information Agent (to customer_proxy_agent):\n",
      "\n",
      "Thank you, Ali from Montreal. Is there anything else you need assistance with?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Replying as customer_proxy_agent. Provide feedback to Onboarding Personal Information Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: no\n",
      "customer_proxy_agent (to Onboarding Personal Information Agent):\n",
      "\n",
      "no\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "********************************************************************************\n",
      "Starting a new chat....\n",
      "\n",
      "********************************************************************************\n",
      "Onboarding Topic preference Agent (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what topics you are interested in reading about?\n",
      "Context: \n",
      "{'name': 'Ali', 'location': 'Montreal'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Replying as customer_proxy_agent. Provide feedback to Onboarding Topic preference Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: About Generative AI\n",
      "customer_proxy_agent (to Onboarding Topic preference Agent):\n",
      "\n",
      "About Generative AI\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "********************************************************************************\n",
      "Starting a new chat....\n",
      "\n",
      "********************************************************************************\n",
      "customer_proxy_agent (to Customer Engagement Agent):\n",
      "\n",
      "Let's find something fun to read.\n",
      "Context: \n",
      "{'name': 'Ali', 'location': 'Montreal'}\n",
      "Ali from Montreal is interested in reading about Generative AI.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Customer Engagement Agent (to customer_proxy_agent):\n",
      "\n",
      "Hey Ali! Did you know that the concept of Generative AI involves machines not only understanding data but also creating new data based on what they've learned? It's like giving machines a creative side! It's fascinating how technology is advancing, right? If you want to dive deeper into this topic, you're in for a mind-blowing journey! Enjoy exploring the world of Generative AI! If you have any questions or need more recommendations, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ca98c",
   "metadata": {},
   "source": [
    "**Print out the summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011c74f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Ali', 'location': 'Montreal'}\n",
      "\n",
      "\n",
      "Ali from Montreal is interested in reading about Generative AI.\n",
      "\n",
      "\n",
      "Ali from Montreal is interested in reading about Generative AI, which involves machines not only understanding data but also creating new data based on what they've learned. Enjoy exploring the world of Generative AI!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f81d14",
   "metadata": {},
   "source": [
    "**Cost Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb2457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_including_cached_inference': {'total_cost': 0.000136, 'gpt-3.5-turbo-0125': {'cost': 0.000136, 'prompt_tokens': 185, 'completion_tokens': 29, 'total_tokens': 214}}, 'usage_excluding_cached_inference': {'total_cost': 0.000136, 'gpt-3.5-turbo-0125': {'cost': 0.000136, 'prompt_tokens': 185, 'completion_tokens': 29, 'total_tokens': 214}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 5.1000000000000006e-05, 'gpt-3.5-turbo-0125': {'cost': 5.1000000000000006e-05, 'prompt_tokens': 66, 'completion_tokens': 12, 'total_tokens': 78}}, 'usage_excluding_cached_inference': {'total_cost': 5.1000000000000006e-05, 'gpt-3.5-turbo-0125': {'cost': 5.1000000000000006e-05, 'prompt_tokens': 66, 'completion_tokens': 12, 'total_tokens': 78}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.000339, 'gpt-3.5-turbo-0125': {'cost': 0.000339, 'prompt_tokens': 273, 'completion_tokens': 135, 'total_tokens': 408}}, 'usage_excluding_cached_inference': {'total_cost': 0.000339, 'gpt-3.5-turbo-0125': {'cost': 0.000339, 'prompt_tokens': 273, 'completion_tokens': 135, 'total_tokens': 408}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.cost)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e5937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
