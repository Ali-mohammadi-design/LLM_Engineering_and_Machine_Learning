{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtn6vr5RoqzFwc98RxGm1W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-mohammadi-design/ML-practice/blob/main/Prompt_Engineering_LangChain_Chat()__PromptTemplate()_for_chat().ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dEtic0S8En3",
        "outputId": "661a5cea-5598-4980-e770-c72b119ed08c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.350 langchain-community-0.0.2 langchain-core-0.1.0 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPlNx4K58Ft0",
        "outputId": "e48e686e-1c1f-4b28-d6d5-f711b03dee18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.9-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "openAI_API_Key=os.environ['openAI_API_Key']"
      ],
      "metadata": {
        "id": "vc7jubhA8MHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openAI_API_Key=os.environ['openAI_API_Key']"
      ],
      "metadata": {
        "id": "hz5C8JpD9rf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAI(openai_api_key=os.environ['openAI_API_Key'], max_tokens=20)"
      ],
      "metadata": {
        "id": "f43jfvnk8VPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm('how is mr gho?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "edwtLQbH8XT6",
        "outputId": "8b8a8a4a-0333-4173-fb15-3c39482e7d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nMr. Gho is doing well, thank you for asking.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "ydcPUJ35-FGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat= ChatOpenAI(openai_api_key=openAI_API_Key)"
      ],
      "metadata": {
        "id": "S8CDsPFI8Zg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LLM function\n",
        "\n",
        "president= 'Donald Trump'\n",
        "print(llm(f\"tell me a fact about {president}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL5K7nyB-Lc5",
        "outputId": "2ddf8efa-7e1c-4e5d-8bb3-52d9fcdf19c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Donald Trump is the 45th President of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using prompt template to include various prompt automatiacally"
      ],
      "metadata": {
        "id": "8ViITPJmHcSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using prompt template\n",
        "from langchain import PromptTemplate\n",
        "input_prompt=PromptTemplate(input_variables=['president'], template='Tell me a fact about {president}')"
      ],
      "metadata": {
        "id": "jA2SLg37Eopw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt.format(president='donal trump')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ms4A6691F6I7",
        "outputId": "c8a788a3-82af-4f24-af0d-2b0649466924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact about donal trump'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt.format(president='Joe Biden')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CPLywGyUG5T4",
        "outputId": "36e3b25b-2493-4ebd-ff55-d9265cf7b23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a fact about Joe Biden'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(input_prompt.format(president='joe biden'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W1tkYWZaHDJ_",
        "outputId": "28af9167-da7c-4b8d-8184-636cd56e626d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nJoe Biden is the oldest president in U'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having multiple variables in a prompt"
      ],
      "metadata": {
        "id": "FZmlEXS5Hsi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multiple_input_prompt=PromptTemplate(input_variables=['president','topic'], template='Tell me a fact about {president} opinion aboout {topic}')"
      ],
      "metadata": {
        "id": "Gp8zA01VHnz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(multiple_input_prompt.format(president='joe biden', topic='Iran'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mHS9XCwIId8e",
        "outputId": "fbcaf835-87a5-4d65-d2e1-cfa7f96a5fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nJoe Biden has expressed a willingness to re-enter the 2015 nuclear deal with Iran if Tehran'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(multiple_input_prompt.format(president='Jimmy Carter', topic='North Krea'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1JojE1JgI2RJ",
        "outputId": "b986c585-c7e9-42ae-88ca-94a0c2de3362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nJimmy Carter has consistently advocated for the United States to engage in direct negotiations with North Korea to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "president_name= input(\"please enter the president's name\")\n",
        "topic_name= input(\"please enter the topic\")\n",
        "llm(multiple_input_prompt.format(president=president_name, topic= topic_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "mhW2fUMVI_1W",
        "outputId": "4cc2ac3f-61c8-4054-b495-024f29656b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "please enter the president's nameJoe Biden\n",
            "please enter the topic Iran\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nJoe Biden has expressed support for the 2015 Iran nuclear deal, which he believes is an effective'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate"
      ],
      "metadata": {
        "id": "WcAfV0lNJ1sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "3ohgC_ckpMHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would setup the template and pass it to the systemmessage template"
      ],
      "metadata": {
        "id": "cjRoit5BsPPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_template='you are an AI recepie assistant who are expert in {diery_preference} food and you can propose the dishes that can be prepared in {minutes} minutes'"
      ],
      "metadata": {
        "id": "-hGbbruZrKex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_mesaage_prompt= SystemMessagePromptTemplate.from_template(system_message)"
      ],
      "metadata": {
        "id": "GcyYrR6KrkdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_template='{food_name}'"
      ],
      "metadata": {
        "id": "IC9p5Am8scSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_message_prompt= HumanMessagePromptTemplate.from_template(human_template)"
      ],
      "metadata": {
        "id": "V_MwDop0sseg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_mesaage_prompt.input_variables"
      ],
      "metadata": {
        "id": "75iYKydPtA_-",
        "outputId": "5ab7959e-a3b4-47ee-84d3-81138f041dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['diery_preference', 'minutes']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_message_prompt.input_variables"
      ],
      "metadata": {
        "id": "8OosTXzGtI9J",
        "outputId": "02be6a42-fcc3-43fb-fc37-c48c59670ea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['food_name']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt= ChatPromptTemplate.from_messages([system_mesaage_prompt,human_message_prompt])"
      ],
      "metadata": {
        "id": "NhjQD4Z5tKgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt.input_variables"
      ],
      "metadata": {
        "id": "G6oXloBTtnGo",
        "outputId": "2ae51f7a-422e-4412-e481-f484d6304a21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['diery_preference', 'food_name', 'minutes']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt.format_prompt(diery_preference='vegan',\n",
        "                          minutes='100',\n",
        "                          food_name='Ghormeh_Sabzi' )"
      ],
      "metadata": {
        "id": "-W7cuFiatwN2",
        "outputId": "1a225cba-c2d2-47cf-8b39-0f0e893815c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='you are an AI recepie assistant who are expert in vegan and you can propose dishes that can be prepared in 100 minutes'), HumanMessage(content='Ghormeh_Sabzi')])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt.format_prompt(diery_preference='vegan',\n",
        "                          minutes='100',\n",
        "                          food_name='Ghormeh_Sabzi' ).to_messages()"
      ],
      "metadata": {
        "id": "FuRLgmgXvnm9",
        "outputId": "8f76ee9d-fada-4b38-b72f-d3508be8f753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='you are an AI recepie assistant who are expert in vegan and you can propose dishes that can be prepared in 100 minutes'),\n",
              " HumanMessage(content='Ghormeh_Sabzi')]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diery_preference=input('please insert your diery_preference \\n ')\n",
        "minutes=input('please insert the time that you can dedicate to cook the food in minutes  \\n')\n",
        "food_name=input('please insert the food name \\n ')\n"
      ],
      "metadata": {
        "id": "N-rHx9haxLGj",
        "outputId": "aafa684d-ebd0-43af-83ab-129f606d3e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "please insert your diery_preference \n",
            " vegan\n",
            "please insert the time that you can dedicate to cook the food in minutes  \n",
            "50\n",
            "please insert the food name \n",
            " kashkeh bademjan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= chat_prompt.format_prompt(diery_preference= diery_preference,\n",
        "                          minutes= minutes,\n",
        "                          food_name= food_name ).to_messages()\n",
        "prompt"
      ],
      "metadata": {
        "id": "HnxIflqJvhQh",
        "outputId": "fe2402a9-f554-4b92-9b29-c6181e720d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='you are an AI recepie assistant who are expert in vegan and you can propose dishes that can be prepared in 50 minutes'),\n",
              " HumanMessage(content='kashkeh bademjan')]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=chat(prompt)"
      ],
      "metadata": {
        "id": "E1G69Um8vtfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.content)"
      ],
      "metadata": {
        "id": "NnYiK-sVwaTJ",
        "outputId": "3cdb1e82-af22-492b-9f33-e70de13f3b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a vegan version of Kashkeh Bademjan that can be prepared in 50 minutes:\n",
            "\n",
            "Ingredients:\n",
            "- 2 medium-sized eggplants\n",
            "- 1 onion, finely chopped\n",
            "- 3 cloves of garlic, minced\n",
            "- 2 tablespoons olive oil\n",
            "- 1 teaspoon turmeric\n",
            "- 1 teaspoon ground cumin\n",
            "- 1 teaspoon paprika\n",
            "- 1 cup tomato sauce\n",
            "- 2 tablespoons tomato paste\n",
            "- 1 tablespoon lemon juice\n",
            "- Salt and pepper to taste\n",
            "- Vegan Kashk (available at specialty stores or online)\n",
            "- Fresh parsley, chopped (for garnish)\n",
            "\n",
            "Instructions:\n",
            "1. Preheat your oven to 400°F (200°C). Cut the eggplants in half lengthwise and place them on a baking sheet lined with parchment paper. Drizzle with olive oil and sprinkle with salt. Roast in the oven for about 25-30 minutes until the flesh is soft and the skin is wrinkled. Remove from the oven and let them cool slightly.\n",
            "  \n",
            "2. While the eggplants are roasting, heat 2 tablespoons of olive oil in a large skillet over medium heat. Add the chopped onion and minced garlic, and sauté until golden brown and fragrant, about 5-7 minutes.\n",
            "\n",
            "3. Once the eggplants have cooled, scoop out the flesh from the skin and add it to the skillet with the onion and garlic mixture. Mash the eggplant with a fork or potato masher until smooth.\n",
            "\n",
            "4. Stir in the turmeric, ground cumin, and paprika. Cook for an additional 2 minutes to allow the spices to release their flavors.\n",
            "\n",
            "5. Add the tomato sauce, tomato paste, and lemon juice to the skillet. Season with salt and pepper to taste. Stir well to combine all the ingredients. Simmer the mixture over low heat for about 10-15 minutes, stirring occasionally.\n",
            "\n",
            "6. Meanwhile, prepare the vegan Kashk according to the instructions on the package.\n",
            "\n",
            "7. Once the Kashk is ready, remove the skillet from the heat and transfer the Kashk Bademjan to a serving dish. Drizzle the vegan Kashk on top and garnish with fresh parsley.\n",
            "\n",
            "8. Serve the Kashkeh Bademjan warm with some bread or rice as a main dish or as a side dish. Enjoy!\n",
            "\n",
            "Note: Kashkeh Bademjan is traditionally served with Persian bread, but you can also enjoy it with pita bread, rice, or any other grain of your choice.\n"
          ]
        }
      ]
    }
  ]
}