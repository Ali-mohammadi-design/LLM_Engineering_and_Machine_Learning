{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df533ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\moham\\anaconda3\\lib\\site-packages (0.27.7)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2022.9.14)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.50-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl.metadata (678 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.10.50 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.50-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl.metadata (604 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.2.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.23-py3-none-any.whl.metadata (610 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.25-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.31-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading aiohttp-3.9.5-cp39-cp39-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.6.3)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.27.0)\n",
      "Collecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading llama_cloud-0.0.6-py3-none-any.whl.metadata (750 bytes)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.26.4)\n",
      "Collecting openai>=1.1.0 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading openai-1.35.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.4.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (9.2.0)\n",
      "Collecting requests>=2.31.0 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.5.2)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core==0.10.50->llama-index)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (4.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.14.1)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.4.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (4.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.3.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50->llama-index) (2.5.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.50->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\moham\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\moham\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index) (2022.7.9)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core==0.10.50->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.50->llama-index) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.50->llama-index) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50->llama-index) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core==0.10.50->llama-index) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.50->llama-index) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core==0.10.50->llama-index) (3.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.50->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.50->llama-index) (2022.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.50->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50->llama-index) (2.14.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core==0.10.50->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.10.50-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.10.50-py3-none-any.whl (15.4 MB)\n",
      "   ---------------------------------------- 15.4/15.4 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.2.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading llama_index_llms_openai-0.1.23-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.25-py3-none-any.whl (37 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading aiohttp-3.9.5-cp39-cp39-win_amd64.whl (371 kB)\n",
      "   ---------------------------------------- 371.6/371.6 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 147.9/147.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "   ---------------------------------------- 176.9/176.9 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 130.8/130.8 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading llama_parse-0.4.4-py3-none-any.whl (8.0 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 1.6/1.6 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
      "   ---------------------------------------- 327.4/327.4 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 290.4/290.4 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 152.8/152.8 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 64.9/64.9 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.31-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.3/78.3 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, tqdm, SQLAlchemy, requests, PyYAML, pypdf, networkx, nest-asyncio, fsspec, distro, deprecated, beautifulsoup4, nltk, aiohttp, openai, llama-cloud, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.39\n",
      "    Uninstalling SQLAlchemy-1.4.39:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.39\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.8.4\n",
      "    Uninstalling networkx-2.8.4:\n",
      "      Successfully uninstalled networkx-2.8.4\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.5\n",
      "    Uninstalling nest-asyncio-1.5.5:\n",
      "      Successfully uninstalled nest-asyncio-1.5.5\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.1\n",
      "    Uninstalling beautifulsoup4-4.11.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.4\n",
      "    Uninstalling aiohttp-3.8.4:\n",
      "      Successfully uninstalled aiohttp-3.8.4\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.7\n",
      "    Uninstalling openai-0.27.7:\n",
      "      Successfully uninstalled openai-0.27.7\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.31 aiohttp-3.9.5 beautifulsoup4-4.12.3 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 fsspec-2024.6.0 llama-cloud-0.0.6 llama-index-0.10.50 llama-index-agent-openai-0.2.7 llama-index-cli-0.1.12 llama-index-core-0.10.50 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.2.1 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.23 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.25 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.4 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.8.1 openai-1.35.3 pypdf-4.2.0 requests-2.32.3 striprtf-0.0.26 tqdm-4.66.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.24 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.24 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
      "conda-repo-cli 1.0.24 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "conda-repo-cli 1.0.24 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "langgraph 0.0.69 requires langchain-core<0.3,>=0.2, but you have langchain-core 0.0.13 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc9c7f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openAI_API_Key=os.environ['openAI_API_Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d151139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"D:\\\\University\\\\Test\\\\1.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c26c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d64df",
   "metadata": {},
   "source": [
    "The following setting is optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51f633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8073126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e6af688",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a406084",
   "metadata": {},
   "source": [
    "**SummaryIndex**\n",
    "\n",
    "\n",
    "The SummaryIndex class is typically used to create an index that summarizes the content of the nodes. This kind of index can be useful for applications where you need a quick overview or summary of large documents or collections of text. The summary might be generated by combining or condensing the information in the nodes.\n",
    "\n",
    "**VectorStoreIndex**\n",
    "\n",
    "The VectorStoreIndex class creates an index that stores vector representations of the nodes. These vectors can be used for various purposes, such as semantic search, similarity matching, and other machine learning tasks. The vector representations are typically created using techniques like word embeddings or sentence embeddings, which transform text into high-dimensional vectors that capture the semantic meaning of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f2b1c",
   "metadata": {},
   "source": [
    "Define Query Engines and Set Metadata:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20804a3",
   "metadata": {},
   "source": [
    "Note:A query engine in the context of llama_index (and similar libraries) is a component that allows you to query an index and retrieve relevant information based on the query. It provides an interface to interact with the indexed data, process queries, and return results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a8ce0",
   "metadata": {},
   "source": [
    "The as_query_engine method essentially configures the index to be queried efficiently. It sets up the necessary components and parameters to handle queries, process them, and return appropriate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f639f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4b3c1",
   "metadata": {},
   "source": [
    "response_mode=\"tree_summarize\": Specifies the mode for generating responses. In this case, it uses a tree summarization method, which likely organizes and summarizes the content in a hierarchical manner.\n",
    "\n",
    "\n",
    "use_async=True: Indicates that the query engine should operate asynchronously, which can be useful for handling multiple queries concurrently or for improving performance in an asynchronous environment.\n",
    "\n",
    "vector_index.as_query_engine\n",
    "Purpose: Creates a query engine for the VectorStoreIndex.\n",
    "Default Parameters: This method does not specify any additional parameters, so it uses the default settings for the query engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebea061",
   "metadata": {},
   "source": [
    "Next we should set our query (prompt) to be quried in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423f375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to TRIZ and its integration\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the TRIZ.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e803672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e98579",
   "metadata": {},
   "source": [
    "The RouterQueryEngine is designed to coordinate and route queries to appropriate tools or query engines (summary_tool and vector_tool in this case). The LLMSingleSelector helps in selecting the appropriate tool based on predefined configurations or defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25d79d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The document seems to focus on summarization questions related to TRIZ and its integration..\n",
      "\u001b[0mThe document discusses the application of Lean Six Sigma and TRIZ methodology in banking services, focusing on improving customer satisfaction, cost efficiency, and process speed. It highlights the integration of TRIZ into the Lean Six Sigma approach to enhance problem-solving in the service industry, particularly in banking services. The case study presented demonstrates the successful implementation of Lean Six Sigma with TRIZ in a savings bank company, resulting in significant improvements in process capability, waiting time reduction, and cost savings. The document emphasizes the importance of investing resources, training employees, and committing to the LSS approach to achieve successful business improvement in service operations.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae69ae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcfdf5ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: TRIZ is known for its problem-solving and innovation techniques, but it may lack the structured approach and data-driven methodology that Six Sigma provides. Integrating TRIZ with Six Sigma can enhance problem-solving capabilities by combining creativity with statistical analysis..\n",
      "\u001b[0mTRIZ methodology is known for its effectiveness in analyzing customer needs and developing innovative solutions to meet those needs. However, in certain areas, such as the service industry, TRIZ can face challenges due to the abstract nature of service contradictions. By integrating TRIZ with Six Sigma, which is focused on process improvement and reducing variation, the weaknesses of TRIZ in addressing service industry problems can be complemented. This integration allows for a more comprehensive approach to problem-solving by combining TRIZ's innovative thinking with Six Sigma's data-driven and systematic methodology.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"why should we integrate TRIZ and six sigma? I mean which part of TRIZ is weak that we should integrate it wiith six sigma?\"\n",
    ")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
