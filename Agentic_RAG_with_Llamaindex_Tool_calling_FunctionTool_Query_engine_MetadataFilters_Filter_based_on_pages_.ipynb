{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7eeafc",
   "metadata": {},
   "source": [
    "Toolcalling enables LLMs to interact with external enviroments through a dynamic interface. Tool calling helps to choose an appropriate tool and make necessary arguments to executing the tool.\n",
    "\n",
    "In tool calling we can equip LLM to select a tool among a set of tools that we have prepared for it and make them to choose proper input for the tool and inject the inputs and return the reults to us. We can also do the tool calling for in the RAG process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b37fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\moham\\anaconda3\\lib\\site-packages (1.35.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\moham\\anaconda3\\lib\\site-packages (0.10.50)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.2.7)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core==0.10.50 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.10.50)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.10)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.2.1)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.23)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.25)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50->llama-index) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (2024.6.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.35.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.4.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (9.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (4.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index) (1.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index) (4.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.3.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50->llama-index) (2.5.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.50->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\moham\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\moham\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.50->llama-index) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.50->llama-index) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.50->llama-index) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50->llama-index) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core==0.10.50->llama-index) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.50->llama-index) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core==0.10.50->llama-index) (3.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.50->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.50->llama-index) (2022.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.50->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50->llama-index) (2.14.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core==0.10.50->llama-index) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "483666e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openAI_API_Key=os.environ['openAI_API_Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1879ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ac87d",
   "metadata": {},
   "source": [
    "When using an agent or LLM with function calling, the tool selected (and the arguments written for that tool) rely strongly on the tool name and description of the tools purpose and arguments. Spending time tuning these parameters can result in larges changes in how the LLM calls these tools.\n",
    "\n",
    "A Tool implements a very generic interface - simply define __call__ and also return some basic metadata (name, description, function schema).\n",
    "\n",
    "We offer a few different types of Tools:\n",
    "\n",
    "FunctionTool: A function tool allows users to easily convert any user-defined function into a Tool. It can also auto-infer the function schema.\n",
    "\n",
    "QueryEngineTool: A tool that wraps an existing query engine. Note: since our agent abstractions inherit from BaseQueryEngine, these tools can also wrap other agents.\n",
    "\n",
    "Community contributed ToolSpecs that define one or more tools around a single service (like Gmail)\n",
    "\n",
    "Utiltiy tools for wrapping other tools to handle returning large amounts of data from a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5058c",
   "metadata": {},
   "source": [
    "On the other words, these tools make other tools properly callable in the LLM. In the following example we have defined two tools in python then made it callable for the LLM with the FunctionTool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7666c6be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def mystery(x: int, y: int) -> int: \n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7da9b0",
   "metadata": {},
   "source": [
    "Note:Predict and call  do tool calling (through text prompting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9535b929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
      "=== Function Output ===\n",
      "121\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool], \n",
    "    \"Tell me the output of the mystery function on 2 and 9\", \n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e135c9",
   "metadata": {},
   "source": [
    "As is clear in the previous example the LLM first select a relevant tool and then call the tool and give it the inputs and returns the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794655b6",
   "metadata": {},
   "source": [
    "Now we want make the RAG functions into the Llama_index callable for the LLM and do the function in the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a138403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"D:\\\\University\\\\Test\\\\1.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d761d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=512)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4e455",
   "metadata": {},
   "source": [
    "Note: Meta data is some data related to the text like page label and file name and etc. Sometimes analyzing the meta data in the RAG procee can increase the accuracy of the RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0032f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: 1.pdf\n",
      "file_path: D:\\University\\Test\\1.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 666613\n",
      "creation_date: 2024-06-06\n",
      "last_modified_date: 2024-06-05\n",
      "\n",
      "The theory of inventive problem solving (TRIZ) is a science that allows creative pro-\n",
      "blems in any ﬁeld of knowledge to be revealed and solved, while developing creative\n",
      "(inventive) thinking skills and a creative personality (Altshuller, 2000). Often at the rootof a problem’s solution lies what seems at ﬁrst glance to be a wild idea. TRIZ gives one\n",
      "the ability not only to be prepared for such ideas, but to create them. TRIZ is the knowl-\n",
      "edge-based, systematic approach to innovation. TRIZ methods are drawn from analysisof the most innovative inventions in different industries, technologies, and ﬁelds of engin-\n",
      "eering. These principles can be used to consciously develop a system along its path of tech-\n",
      "nical evolution. It has been proved that TRIZ is a powerful problem-solving methodologythrough its development over about 60 years. TRIZ provides people with a dialectic way of\n",
      "thinking, which guides us to understand the problem as a system, to get an image of the ideal\n",
      "solution ﬁrst and to promote the performance of products by solving contradictions. Domband Dettmer (1999) reported that inventors using TRIZ experienced an improvement of\n",
      "70% to 300% or more in the number of creative ideas that they generated for solving tech-\n",
      "nical problems and in the speed with which they generated innovative ideas.\n",
      "Many researches that integrate or compare TRIZ with different creativity tools,\n",
      "methods and philosophies have shown that TRIZ provides the most useful help to\n",
      "designers for developing high-level products and service application as well. Manufactur-ing is an area wherein one can easily ﬁnd applications of TRIZ integrated with problem-\n",
      "solving tools (Stratton & Mann, 2003; Stratton & Warburton, 2003). During the\n",
      "application, it is important to deﬁne the conﬂicts, and then based on the conﬂicts, todevelop innovative solutions. The service industry is an area where TRIZ is difﬁcult to\n",
      "apply; but along with its fast development and its integration with problem-solving\n",
      "tools, integrated methods have been applied in this area (King, 2004).\n"
     ]
    }
   ],
   "source": [
    "print(nodes[6].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76caaf5e",
   "metadata": {},
   "source": [
    "Note:Query engine is a generic interface that allows you to ask question over your data.\n",
    "\n",
    "A query engine takes in a natural language query, and returns a rich response. It is most often (but not always) built on one or many indexes via retrievers. You can compose multiple query engines to achieve more advanced capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c8aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a378f",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "MetadataFilters is  designed to help manage and apply metadata-based filtering to vector stores. \n",
    "\n",
    "filters=MetadataFilters.from_dicts: This parameter applies metadata filtering. The MetadataFilters.from_dicts method creates a filter from a list of dictionaries, each specifying a key-value pair for filtering. In this case, the filter will only consider vectors with the metadata key page_label set to \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0e7bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    filters=MetadataFilters.from_dicts(\n",
    "        [\n",
    "            {\"key\": \"page_label\", \"value\": \"1\"}\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"WHat is TRIZ and why should we integrate it with the six sigma?\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d60d011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIZ is an effective method for analyzing customer needs and developing innovative solutions to meet those needs. It provides a structured approach to problem-solving and encourages creative thinking. Integrating TRIZ with Six Sigma can enhance the traditional techniques of Six Sigma by bringing in a systematic innovation methodology that can help identify and resolve conflicts more effectively, leading to improved problem-solving and innovative solutions in various industries, including banking services.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b48d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef141bc9",
   "metadata": {},
   "source": [
    "Note: we can make the meta data filter callable for the LLM and ask the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be382cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "\n",
    "\n",
    "def vector_query(\n",
    "    query: str, \n",
    "    page_numbers: List[str]\n",
    ") -> str:\n",
    "    \"\"\"Perform a vector search over an index.\n",
    "    \n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
    "        over all pages. Otherwise, filter by the set of specified pages.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = [\n",
    "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
    "    ]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts,\n",
    "            condition=FilterCondition.OR\n",
    "        )\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "    \n",
    "\n",
    "vector_query_tool = FunctionTool.from_defaults(\n",
    "    name=\"vector_tool\",\n",
    "    fn=vector_query\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fa68308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"integration of TRIZ and Six Sigma\", \"page_numbers\": []}\n",
      "=== Function Output ===\n",
      "The integration of TRIZ and Six Sigma has been shown to be effective in improving banking services. This combination enhances traditional Lean Six Sigma techniques by providing innovative solutions to meet customer needs and improve processes.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool], \n",
    "    ''' please consider all pages in this paper and give me a comprehensive definition for the integration of TRIZ and Six Sigma''', \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8728164",
   "metadata": {},
   "source": [
    "As is clear here the LLM select the tool and then call and input the tool with the inputs that it has selected for the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0276ea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30361bad",
   "metadata": {},
   "source": [
    "We can also add other tools to the tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c979102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful if you want to get a summary of MetaGPT\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b5cc809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"query\": \"integration of TRIZ and Six Sigma\", \"page_numbers\": []}\n",
      "=== Function Output ===\n",
      "The integration of TRIZ and Six Sigma has been shown to be effective in improving banking services. This combination enhances traditional Lean Six Sigma techniques by providing innovative solutions to meet customer needs and improve service quality and speed. The application of Lean Six Sigma methodology with TRIZ has proven to be successful in enhancing the overall performance of banking services.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \n",
    "    ''' please consider all pages in this paper and give me a comprehensive definition for the integration of TRIZ and Six Sigma''', \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fd2be62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: summary_tool with args: {\"input\": \"TRIZ\"}\n",
      "=== Function Output ===\n",
      "TRIZ is a problem-solving methodology that allows for creative solutions to be developed by revealing and solving creative problems. It focuses on developing inventive thinking skills and a creative personality. TRIZ is effective in analyzing customer needs and developing innovative solutions to meet those needs. It has been successfully applied in various industries and fields over the past 60 years, providing a systematic approach to innovation. TRIZ helps individuals understand problems as systems, visualize ideal solutions, and enhance product performance by resolving contradictions.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [vector_query_tool, summary_tool], \n",
    "    \n",
    "    '''give me a comprehensive definition of TRIZ''', \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8f703a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n",
      "{'page_label': '1', 'file_name': '1.pdf', 'file_path': 'D:\\\\University\\\\Test\\\\1.pdf', 'file_type': 'application/pdf', 'file_size': 666613, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-05'}\n"
     ]
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    print(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f8af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
