{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb1ff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in c:\\users\\moham\\anaconda3\\lib\\site-packages (0.2.33)\n",
      "Requirement already satisfied: diskcache in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (7.1.0)\n",
      "Requirement already satisfied: flaml in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (1.35.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (23.2)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (2.5.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (1.0.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (2.4.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pyautogen) (0.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.14.5)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from docker->pyautogen) (306)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from docker->pyautogen) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from docker->pyautogen) (1.26.11)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tiktoken->pyautogen) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2022.9.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\anaconda3\\lib\\site-packages (from requests>=2.26.0->docker->pyautogen) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\moham\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.3->pyautogen) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c2c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openAI_API_Key=os.environ['openAI_API_Key']\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7026b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1151733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daca8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200e7b8",
   "metadata": {},
   "source": [
    "Note:  human_input_mode=\"NEVER\" means the agent doesnot need human response before go ahead and it continues by it self!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6b9273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0464fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, please provide me with the joke you'd like me to repeat.\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570d01a",
   "metadata": {},
   "source": [
    "As is clear we do not have any conversation. How can we make a conversation among the agents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4dd504",
   "metadata": {},
   "source": [
    "**Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f535f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853f71ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe, great to meet you! Let's dive into some laughs together. So, I recently learned that laughter is the best medicine. Unless you're laughing for no reason, then they just call it weird.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Well, Cathy, I agree with you on that! It's weird unless you're a stand-up comedian, then they call it a job.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Haha, you got that right, Joe! Being a stand-up comedian means I get to make people laugh for a living. So, in a way, my job description is basically \"professional weirdo.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d44a3d6",
   "metadata": {},
   "source": [
    "**Printing Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffae5d4",
   "metadata": {},
   "source": [
    "You can print out:\n",
    "\n",
    "Chat history\n",
    "\n",
    "Cost\n",
    "\n",
    "Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4539724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Hey Joe, great to meet you! Let's dive into some laughs \"\n",
      "             'together. So, I recently learned that laughter is the best '\n",
      "             \"medicine. Unless you're laughing for no reason, then they just \"\n",
      "             'call it weird.',\n",
      "  'role': 'user'},\n",
      " {'content': \"Well, Cathy, I agree with you on that! It's weird unless you're \"\n",
      "             'a stand-up comedian, then they call it a job.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Haha, you got that right, Joe! Being a stand-up comedian means I '\n",
      "             'get to make people laugh for a living. So, in a way, my job '\n",
      "             'description is basically \"professional weirdo.\"',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f803f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 114,\n",
      "                                                             'cost': 0.000295,\n",
      "                                                             'prompt_tokens': 248,\n",
      "                                                             'total_tokens': 362},\n",
      "                                      'total_cost': 0.000295},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 114,\n",
      "                                                             'cost': 0.000295,\n",
      "                                                             'prompt_tokens': 248,\n",
      "                                                             'total_tokens': 362},\n",
      "                                      'total_cost': 0.000295}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "542c3469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Haha, you got that right, Joe! Being a stand-up comedian means I get to make '\n",
      " 'people laugh for a living. So, in a way, my job description is basically '\n",
      " '\"professional weirdo.\"')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c92a16",
   "metadata": {},
   "source": [
    "**Get a better summary of the conversation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bbd011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe, great to meet you! Let's dive into some laughs together. So, I recently learned that laughter is the best medicine. Unless you're laughing for no reason, then they just call it weird.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Well, Cathy, I agree with you on that! It's weird unless you're a stand-up comedian, then they call it a job.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Haha, you got that right, Joe! Being a stand-up comedian means I get to make people laugh for a living. So, in a way, my job description is basically \"professional weirdo.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662aca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Laughter is the best medicine, unless you're laughing for no reason, then \"\n",
      " \"it's just weird or part of being a stand-up comedian.\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d69a6",
   "metadata": {},
   "source": [
    "**Chat Termination**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386693d6",
   "metadata": {},
   "source": [
    "Chat can be terminated using a termination conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb7953a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "178ea997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe! Why was the math book sad? Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, that's a good one, Cathy! I love math jokes. So, have you heard about the claustrophobic astronaut? He just needed a little space!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Haha, that's a great one, Joe! I guess he needed some breathing room up there!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Exactly, Cathy! He needed to space out a bit more. So, tell me, do you have any good jokes up your sleeve?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Of course, Joe! How does a penguin build its house? Igloos it together!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, that's a cute one, Cathy! I love penguin jokes. Thanks for sharing that!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Glad you enjoyed it, Joe! Penguins are always cool for a good laugh!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Absolutely, Cathy! Penguins are cool and funny creatures. Well, it's been great sharing jokes with you, but I gotta go. Have a wonderful day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dcc51f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cathy (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "The last joke we talked about was: How does a penguin build its house? It igloos it together!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Thanks, Joe! Have a fantastic day, and keep those jokes coming!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Thank you, Cathy! I'll keep the jokes coming for sure. Have a fantastic day too! Take care!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "You too, Joe! Bye now!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Goodbye, Cathy! See you soon!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
