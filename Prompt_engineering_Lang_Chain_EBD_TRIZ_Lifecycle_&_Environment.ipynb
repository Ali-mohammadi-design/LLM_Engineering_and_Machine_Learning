{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3yckOAXF5jcFJvwfHZvjt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-mohammadi-design/Prompt_Engineering_and_Machine_Learning/blob/main/Prompt_engineering_Lang_Chain_EBD_TRIZ_Lifecycle_%26_Environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**with this ability in openai we can automatically pars out the out put in the shape of jason**"
      ],
      "metadata": {
        "id": "A9PTbON_S_kq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOdTUqbYxETP",
        "outputId": "d34dbfb2-c56c-4e71-f511-a4c685c7824f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.6-py3-none-any.whl (811 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.8/811.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.18 (from langchain)\n",
            "  Downloading langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.22 (from langchain)\n",
            "  Downloading langchain_core-0.1.22-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.6 langchain-community-0.0.19 langchain-core-0.1.22 langsmith-0.0.87 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.12.0\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=40d79b60c6f6a24b4975a612d5c8d509dc6ebb4f3554512bb12567fd81910f1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install wikipedia\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "openAI_API_Key=os.environ['openAI_API_Key']"
      ],
      "metadata": {
        "id": "3QJn-p2C7nfj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "3ZAHAOVtIqAG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatOpenAI(openai_api_key=openAI_API_Key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZPTW1uwIp8g",
        "outputId": "03fc879c-5e6b-43ce-fc60-c6155ea22420"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class object_lifecycle():\n",
        "  def __init__(self,First_stage,Second_stage,Third_stage,Fourth_stage):\n",
        "     self.first_stage =First_stage\n",
        "     self.Second_stage=Second_stage\n",
        "     self.Third_stage=Third_stage\n",
        "     self.Fourth_stage=Fourth_stage\n"
      ],
      "metadata": {
        "id": "y_c61Fn0Ip6V"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: in general if we ask the GPT to give us the name of an american scientist it gives us some sentences to introduce the scientist. However, with this method the output is according to the JSON format. like the following format. The LLM specifically returns the property part of the below dictionary. The required specifies what is required to be returned."
      ],
      "metadata": {
        "id": "Q7bDnLMBMx3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_schema={'title':'scientist',\n",
        "             'description':'four stages of the creation of the object',\n",
        "             'type':'object',\n",
        "             'properties':{\n",
        "                 'first_stage': {'title':'first_stage','description':'The First stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'second_stage': {'title':'Second_stage','description':'The second stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'third_stage': {'title':'third_stage','description':'The third stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'last_stage': {'title':'last_stage','description':'The last stage of the lifecycle of this object','data_type':'string'},\n",
        "             },\n",
        "\n",
        "             'required':['first_stage','second_stage','thrid stage','last stage']\n",
        "             }\n"
      ],
      "metadata": {
        "id": "9Uv3kdd5Ip4J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate"
      ],
      "metadata": {
        "id": "tX0V6ZDaF6GJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.openai_functions import create_structured_output_chain"
      ],
      "metadata": {
        "id": "mtfivPbIGO-1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_template=\" you are an AI assistant that could help designers to understand the lifecycle of {objects}. You would explain the lifecycle of {objects} clearly and very breifly in just four stages and provide a  short explanation for every stage \"\n",
        "system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "human_template= 'I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of {objects}'\n",
        "human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])"
      ],
      "metadata": {
        "id": "3fdVh0LBFzpY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=create_structured_output_chain(json_schema,llm, chat_prompt,verbose=True)"
      ],
      "metadata": {
        "id": "icnrJ_vTIpsi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=chain.run(objects='chair')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTNVUz07Ipib",
        "outputId": "356c4d87-fb88-494f-db82-adf93d21372d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem:  you are an AI assistant that could help designers to understand the lifecycle of chair. You would explain the lifecycle of chair clearly and very breifly in just four stages and provide a  short explanation for every stage \n",
            "Human: I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of chair\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxqGRaY9PRE-",
        "outputId": "d9f40d27-424b-488b-8888-11581de2feea"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first_stage': 'Raw Materials',\n",
              " 'second_stage': 'Manufacturing',\n",
              " 'third_stage': 'Use',\n",
              " 'last_stage': 'Disposal'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['first_stage']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QgTJ886GHW9G",
        "outputId": "27f67fce-6c20-4aad-ca97-f81b26e14bb0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Raw Materials'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chair=object_lifecycle(result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage'])"
      ],
      "metadata": {
        "id": "B1dLziolQFUE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment of the Object"
      ],
      "metadata": {
        "id": "cknFcN4RJAdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_template=\" Every {objects} is related to it's environment. we would have three types of environment: 1- built environment, 2-human environment 3- nature environment.Built environment: Every thing directly related to the {objects} and made by human. Human environment: Every human being directly related to the {objects}. Nature environment: every natural things like weather, water etc that is directly connect to {objects}. When we wnat to describe the environment of {objects} we have to show the relation between {objects} and the environment in senctnces.  you are an AI assistant that could help designers to understand the environment of {objects}. You would explain the environment of {objects} with single sentences.\"\n",
        "system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "human_template= ' {lifecycle_stage} is one of the stages of lifecycle of {objects}. Consider {objects} in this stage and determine every part of the environment of {objects} in the separate sentences'\n",
        "human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])"
      ],
      "metadata": {
        "id": "ozvBsN6Ngh5l"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_request= chat_prompt.format_prompt(lifecycle_stage=chair.first_stage, objects='chair').to_messages()"
      ],
      "metadata": {
        "id": "tl3z6E--JUM1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= ChatOpenAI(openai_api_key=openAI_API_Key, max_tokens=150, temperature=0)"
      ],
      "metadata": {
        "id": "keYYgTHGJlpJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=model(model_request)\n",
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "2P4b-LdOJar1",
        "outputId": "38f115e3-b28a-4242-8e33-089c4fb0a3ce"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1. The built environment of the chair in the raw materials stage includes the factories and manufacturing facilities where the materials are sourced and processed.\\n2. The human environment of the chair in the raw materials stage involves the workers and laborers involved in extracting, refining, and transporting the materials used in the chair.\\n3. The nature environment of the chair in the raw materials stage encompasses the natural resources such as wood, metal, or plastic that are harvested or mined to create the chair's components.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As a separate function**"
      ],
      "metadata": {
        "id": "9zbj0SVrKaVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.openai_functions import create_structured_output_chain\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
        "llm=ChatOpenAI(openai_api_key=openAI_API_Key)\n",
        "model= ChatOpenAI(openai_api_key=openAI_API_Key, max_tokens=150, temperature=0)"
      ],
      "metadata": {
        "id": "mmw4Iat7KyKO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class object_lifecycle():\n",
        "  def __init__(self,First_stage,Second_stage,Third_stage,Fourth_stage):\n",
        "     self.first_stage =First_stage\n",
        "     self.Second_stage=Second_stage\n",
        "     self.Third_stage=Third_stage\n",
        "     self.Fourth_stage=Fourth_stage"
      ],
      "metadata": {
        "id": "Q2wgEDOIK6na"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_schema={'title':'scientist',\n",
        "             'description':'four stages of the creation of the object',\n",
        "             'type':'object',\n",
        "             'properties':{\n",
        "                 'first_stage': {'title':'first_stage','description':'The First stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'second_stage': {'title':'Second_stage','description':'The second stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'third_stage': {'title':'third_stage','description':'The third stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'last_stage': {'title':'last_stage','description':'The last stage of the lifecycle of this object','data_type':'string'},\n",
        "             },\n",
        "\n",
        "             'required':['first_stage','second_stage','thrid stage','last stage']\n",
        "             }"
      ],
      "metadata": {
        "id": "CY5CFUz_K-aj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this function we get the object and we would give the life cycle of the object"
      ],
      "metadata": {
        "id": "8CnSr4xsQpMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def object_lifecylce2(name):\n",
        "  system_template=\" you are an AI assistant that could help designers to understand the lifecycle of {objects}. You would explain the lifecycle of {objects} clearly and very breifly in just four stages and provide a  short explanation for every stage \"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= 'I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of {objects}'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  chain=create_structured_output_chain(json_schema,llm, chat_prompt,verbose=True)\n",
        "  result=chain.run(objects=name)\n",
        "  obj=object_lifecycle(result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage'])\n",
        "  return result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage']"
      ],
      "metadata": {
        "id": "gK2-ID0GJbac"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_lifecylce2(chair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGIMpCa6KmQr",
        "outputId": "3d4f95a0-c716-483d-84ed-9e248f054e91"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem:  you are an AI assistant that could help designers to understand the lifecycle of <__main__.object_lifecycle object at 0x7b9b372092d0>. You would explain the lifecycle of <__main__.object_lifecycle object at 0x7b9b372092d0> clearly and very breifly in just four stages and provide a  short explanation for every stage \n",
            "Human: I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of <__main__.object_lifecycle object at 0x7b9b372092d0>\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Creation', 'Utilization', 'Modification', 'Destruction')"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following function we would get the one stage of the object and the name of the object and we would recieve the environment objects"
      ],
      "metadata": {
        "id": "QtVU_KwSQzT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def object_environment(Life_cycle_level,Object_name):\n",
        "  system_template=\" Every {objects} is related to it's environment. we would have three types of environment: 1- built environment, 2-human environment 3- nature environment.Built environment: Every thing directly related to the {objects} and made by human. Human environment: Every human being directly related to the {objects}. Nature environment: every natural things like weather, water etc that is directly connect to {objects}. When we wnat to describe the environment of {objects} we have to show the relation between {objects} and the environment in senctnces.  you are an AI assistant that could help designers to understand the environment of {objects}. You would explain the environment of {objects} with single sentences.\"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= ' {lifecycle_stage} is one of the stages of lifecycle of {objects}. Consider {objects} in this stage and determine every part of the environment of {objects} in the separate sentences'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  model_request= chat_prompt.format_prompt(lifecycle_stage=Life_cycle_level, objects=Object_name).to_messages()\n",
        "  result=model(model_request)\n",
        "  return result"
      ],
      "metadata": {
        "id": "WQPyfQCPLnV1"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_environment('creation','chair')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL_thjzjPVa1",
        "outputId": "5a50ee91-a53a-48ec-c045-b13a835801a2"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"1. In the built environment, the chair is surrounded by tools, materials, and machinery used in its creation.\\n2. In the human environment, designers, craftsmen, and workers collaborate to bring the chair to life through their skills and expertise.\\n3. In the nature environment, the chair's creation requires the use of natural resources such as wood, metal, or plastic, which are sourced from the earth.\")"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Both two functions together**"
      ],
      "metadata": {
        "id": "J1EC5SrsQf23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obj(name):\n",
        "  system_template=\" you are an AI assistant that could help designers to understand the lifecycle of {objects}. You would explain the lifecycle of {objects} clearly and very breifly in just four stages and provide a  short explanation for every stage \"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= 'I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of {objects}'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  chain=create_structured_output_chain(json_schema,llm, chat_prompt,verbose=True)\n",
        "  result=chain.run(objects=name)\n",
        "  obj=object_lifecycle(result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage'])\n",
        "\n",
        "\n",
        "  system_template=\" Every {objects} is related to it's environment. we would have three types of environment: 1- built environment, 2-human environment 3- nature environment.Built environment: Every thing directly related to the {objects} and made by human. Human environment: Every human being directly related to the {objects}. Nature environment: every natural things like weather, water etc that is directly connect to {objects}. When we wnat to describe the environment of {objects} we have to show the relation between {objects} and the environment in senctnces.  you are an AI assistant that could help designers to understand the environment of {objects}. You would explain the environment of {objects} with single sentences.\"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= ' {lifecycle_stage} is one of the stages of lifecycle of {objects}. Consider {objects} in this stage and determine every part of the environment of {objects} in the separate sentences'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  model_request= chat_prompt.format_prompt(lifecycle_stage=result['first_stage'], objects=name).to_messages()\n",
        "  result=model(model_request)\n",
        "  return print(result)"
      ],
      "metadata": {
        "id": "Sdgwjz8EPc_N"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj(chair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgbiT6DHQBkl",
        "outputId": "567071d3-0c8b-4414-a399-3b25415b496e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem:  you are an AI assistant that could help designers to understand the lifecycle of <__main__.object_lifecycle object at 0x7b9b372092d0>. You would explain the lifecycle of <__main__.object_lifecycle object at 0x7b9b372092d0> clearly and very breifly in just four stages and provide a  short explanation for every stage \n",
            "Human: I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of <__main__.object_lifecycle object at 0x7b9b372092d0>\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "content='1. In the built environment, during the initialization stage, <__main__.object_lifecycle object at 0x7b9b372092d0> may be located in a specific physical space or structure designed to support its functioning.\\n\\n2. In the human environment, during the initialization stage, designers or developers may be involved in setting up and configuring <__main__.object_lifecycle object at 0x7b9b372092d0> to meet specific requirements or objectives.\\n\\n3. In the nature environment, during the initialization stage, factors such as temperature, humidity, or other natural conditions may influence the performance or behavior of <__main__.object_lifecycle object at 0x7b9b372092d0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRQavVKpQEbu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}