{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIeG1qJ8VX7/9EcJK3Ev+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-mohammadi-design/Prompt_Engineering_and_Machine_Learning/blob/main/Prompt_engineering_Lang_Chain_EBD_TRIZ_Lifecycle_%26_Environment_Comprehensive_Function_Version2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOdTUqbYxETP",
        "outputId": "4f86aa79-c34f-486b-cb21-b86babdfb1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.6-py3-none-any.whl (811 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/811.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/811.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m655.4/811.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.8/811.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.18 (from langchain)\n",
            "  Downloading langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.22 (from langchain)\n",
            "  Downloading langchain_core-0.1.22-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.6 langchain-community-0.0.19 langchain-core-0.1.22 langsmith-0.0.87 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.12.0\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=38cba60465a1e56d0a1ac16d6fdf9411c22829b76ae014c66d73073fd87ef064\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install wikipedia\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "openAI_API_Key=os.environ['openAI_API_Key']"
      ],
      "metadata": {
        "id": "3QJn-p2C7nfj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "3ZAHAOVtIqAG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatOpenAI(openai_api_key=openAI_API_Key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZPTW1uwIp8g",
        "outputId": "fb50afc0-e1c5-44d7-d360-cf7232267309"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class object_lifecycle():\n",
        "  def __init__(self,First_stage,Second_stage,Third_stage,Fourth_stage):\n",
        "     self.first_stage =First_stage\n",
        "     self.Second_stage=Second_stage\n",
        "     self.Third_stage=Third_stage\n",
        "     self.Fourth_stage=Fourth_stage\n"
      ],
      "metadata": {
        "id": "y_c61Fn0Ip6V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_schema={'title':'scientist',\n",
        "             'description':'four stages of the creation of the object',\n",
        "             'type':'object',\n",
        "             'properties':{\n",
        "                 'first_stage': {'title':'first_stage','description':'The First stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'second_stage': {'title':'Second_stage','description':'The second stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'third_stage': {'title':'third_stage','description':'The third stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'last_stage': {'title':'last_stage','description':'The last stage of the lifecycle of this object','data_type':'string'},\n",
        "             },\n",
        "\n",
        "             'required':['first_stage','second_stage','thrid stage','last stage']\n",
        "             }\n"
      ],
      "metadata": {
        "id": "9Uv3kdd5Ip4J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate"
      ],
      "metadata": {
        "id": "tX0V6ZDaF6GJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.openai_functions import create_structured_output_chain"
      ],
      "metadata": {
        "id": "mtfivPbIGO-1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_template=\" you are an AI assistant that could help designers to understand the lifecycle of {objects}. You would explain the lifecycle of {objects} clearly and very breifly in just four stages and provide a  short explanation for every stage \"\n",
        "system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "human_template= 'I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of {objects}'\n",
        "human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])"
      ],
      "metadata": {
        "id": "3fdVh0LBFzpY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=create_structured_output_chain(json_schema,llm, chat_prompt,verbose=True)"
      ],
      "metadata": {
        "id": "icnrJ_vTIpsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bb9de9-b9ee-48f6-9277-4d3c7548afcb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `create_structured_output_chain` was deprecated in LangChain 0.1.1 and will be removed in 0.2.0. Use create_structured_output_runnable instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=chain.run(objects='chair')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTNVUz07Ipib",
        "outputId": "faa54872-99d4-4344-d00d-455dbc3038e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem:  you are an AI assistant that could help designers to understand the lifecycle of chair. You would explain the lifecycle of chair clearly and very breifly in just four stages and provide a  short explanation for every stage \n",
            "Human: I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of chair\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxqGRaY9PRE-",
        "outputId": "93f2048c-f180-4ad9-aba9-9718a909e8a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first_stage': 'Material Extraction',\n",
              " 'second_stage': 'Manufacturing',\n",
              " 'third_stage': 'Use',\n",
              " 'last_stage': 'Disposal'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['first_stage']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QgTJ886GHW9G",
        "outputId": "d0b23fe7-0d67-4d79-ee2a-59b7eadc9962"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Material Extraction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chair=object_lifecycle(result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage'])"
      ],
      "metadata": {
        "id": "B1dLziolQFUE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment of the Object"
      ],
      "metadata": {
        "id": "cknFcN4RJAdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_template=\" Every {objects} is related to it's environment. we would have three types of environment: 1- built environment, 2-human environment 3- nature environment.Built environment: Every thing directly related to the {objects} and made by human. Human environment: Every human being directly related to the {objects}. Nature environment: every natural things like weather, water etc that is directly connect to {objects}. When we wnat to describe the environment of {objects} we have to show the relation between {objects} and the environment in senctnces.  you are an AI assistant that could help designers to understand the environment of {objects}. You would explain the environment of {objects} with single sentences.\"\n",
        "system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "human_template= ' {lifecycle_stage} is one of the stages of lifecycle of {objects}. Consider {objects} in this stage and determine every part of the environment of {objects} in the separate sentences'\n",
        "human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])"
      ],
      "metadata": {
        "id": "ozvBsN6Ngh5l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_request= chat_prompt.format_prompt(lifecycle_stage=chair.first_stage, objects='chair').to_messages()"
      ],
      "metadata": {
        "id": "tl3z6E--JUM1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= ChatOpenAI(openai_api_key=openAI_API_Key, max_tokens=150, temperature=0)"
      ],
      "metadata": {
        "id": "keYYgTHGJlpJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=model(model_request)\n",
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "2P4b-LdOJar1",
        "outputId": "423550c4-c599-4c9c-fee4-1302cb3e116a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1. In the built environment, the chair's materials are sourced from various locations, such as forests for wood or mines for metals.\\n2. In the human environment, workers are involved in the extraction process, harvesting and processing the materials needed for the chair.\\n3. In the nature environment, the extraction of materials for the chair can have an impact on ecosystems, such as deforestation or habitat disruption.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As a separate function**"
      ],
      "metadata": {
        "id": "9zbj0SVrKaVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.openai_functions import create_structured_output_chain\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
        "llm=ChatOpenAI(openai_api_key=openAI_API_Key)\n",
        "model= ChatOpenAI(openai_api_key=openAI_API_Key, max_tokens=150, temperature=0)"
      ],
      "metadata": {
        "id": "mmw4Iat7KyKO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class object_lifecycle():\n",
        "  def __init__(self,First_stage,Second_stage,Third_stage,Fourth_stage):\n",
        "     self.first_stage =First_stage\n",
        "     self.Second_stage=Second_stage\n",
        "     self.Third_stage=Third_stage\n",
        "     self.Fourth_stage=Fourth_stage"
      ],
      "metadata": {
        "id": "Q2wgEDOIK6na"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_schema={'title':'scientist',\n",
        "             'description':'four stages of the creation of the object',\n",
        "             'type':'object',\n",
        "             'properties':{\n",
        "                 'first_stage': {'title':'first_stage','description':'The First stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'second_stage': {'title':'Second_stage','description':'The second stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'third_stage': {'title':'third_stage','description':'The third stage of the lifecycle of this object','data_type':'string'},\n",
        "                 'last_stage': {'title':'last_stage','description':'The last stage of the lifecycle of this object','data_type':'string'},\n",
        "             },\n",
        "\n",
        "             'required':['first_stage','second_stage','thrid stage','last stage']\n",
        "             }"
      ],
      "metadata": {
        "id": "CY5CFUz_K-aj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this function we get the object and we would give the life cycle of the object"
      ],
      "metadata": {
        "id": "8CnSr4xsQpMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def object_lifecylce2(name):\n",
        "  system_template=\" you are an AI assistant that could help designers to understand the lifecycle of {objects}. You would explain the lifecycle of {objects} clearly and very breifly in just four stages and provide a  short explanation for every stage \"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= 'I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of {objects}'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  chain=create_structured_output_chain(json_schema,llm, chat_prompt,verbose=True)\n",
        "  result=chain.run(objects=name)\n",
        "  obj=object_lifecycle(result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage'])\n",
        "  return result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage']"
      ],
      "metadata": {
        "id": "gK2-ID0GJbac"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_lifecylce2(chair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGIMpCa6KmQr",
        "outputId": "6f6228b3-9ae7-43e5-e73e-60307728af7e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem:  you are an AI assistant that could help designers to understand the lifecycle of <__main__.object_lifecycle object at 0x7d9888657820>. You would explain the lifecycle of <__main__.object_lifecycle object at 0x7d9888657820> clearly and very breifly in just four stages and provide a  short explanation for every stage \n",
            "Human: I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of <__main__.object_lifecycle object at 0x7d9888657820>\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Creation', 'Usage', 'Modification', 'Destruction')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following function we would get the one stage of the object and the name of the object and we would recieve the environment objects"
      ],
      "metadata": {
        "id": "QtVU_KwSQzT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def object_environment(Life_cycle_level,Object_name):\n",
        "  system_template=\" Every {objects} is related to it's environment. we would have three types of environment: 1- built environment, 2-human environment 3- nature environment.Built environment: Every thing directly related to the {objects} and made by human. Human environment: Every human being directly related to the {objects}. Nature environment: every natural things like weather, water etc that is directly connect to {objects}. When we wnat to describe the environment of {objects} we have to show the relation between {objects} and the environment in senctnces.  you are an AI assistant that could help designers to understand the environment of {objects}. You would explain the environment of {objects} with single sentences.\"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= ' {lifecycle_stage} is one of the stages of lifecycle of {objects}. Consider {objects} in this stage and determine every part of the environment of {objects} in the separate sentences'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  model_request= chat_prompt.format_prompt(lifecycle_stage=Life_cycle_level, objects=Object_name).to_messages()\n",
        "  result=model(model_request)\n",
        "  return result"
      ],
      "metadata": {
        "id": "WQPyfQCPLnV1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_environment('creation','chair')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL_thjzjPVa1",
        "outputId": "5bef317b-7ff6-4207-8288-f5990bfd73b6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"1. In the built environment, the chair is surrounded by tools, materials, and machinery used in its creation.\\n2. In the human environment, designers, craftsmen, and workers collaborate to bring the chair to life through their skills and expertise.\\n3. In the nature environment, the chair's creation requires the use of natural resources such as wood, metal, or plastic, which are sourced from the earth.\")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Both two functions together**"
      ],
      "metadata": {
        "id": "J1EC5SrsQf23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obj(name):\n",
        "  system_template=\" you are an AI assistant that could help designers to understand the lifecycle of {objects}. You would explain the lifecycle of {objects} clearly and very breifly in just four stages and provide a  short explanation for every stage \"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= 'I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of {objects}'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  chain=create_structured_output_chain(json_schema,llm, chat_prompt,verbose=True)\n",
        "  result=chain.run(objects=name)\n",
        "  obj=object_lifecycle(result['first_stage'],result['second_stage'],result['third_stage'],result['last_stage'])\n",
        "\n",
        "\n",
        "  system_template=\" Every {objects} is related to it's environment. we would have three types of environment: 1- built environment, 2-human environment 3- nature environment.Built environment: Every thing directly related to the {objects} and made by human. Human environment: Every human being directly related to the {objects}. Nature environment: every natural things like weather, water etc that is directly connect to {objects}. When we wnat to describe the environment of {objects} we have to show the relation between {objects} and the environment in senctnces.  you are an AI assistant that could help designers to understand the environment of {objects}. You would explain the environment of {objects} with single sentences.\"\n",
        "  system_message_prompt= SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template= ' {lifecycle_stage} is one of the stages of lifecycle of {objects}. Consider {objects} in this stage and determine every part of the environment of {objects} in the separate sentences'\n",
        "  human_prompt= HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt, human_prompt])\n",
        "  model_request= chat_prompt.format_prompt(lifecycle_stage=obj.first_stage, objects=name).to_messages()\n",
        "  env_in_first_stage=model(model_request)\n",
        "\n",
        "  model_request2= chat_prompt.format_prompt(lifecycle_stage=obj.Second_stage, objects=name).to_messages()\n",
        "  env_in_second_stage=model(model_request2)\n",
        "\n",
        "  model_request3= chat_prompt.format_prompt(lifecycle_stage=obj.Third_stage, objects=name).to_messages()\n",
        "  env_in_third_stage=model(model_request3)\n",
        "\n",
        "  model_request4= chat_prompt.format_prompt(lifecycle_stage=obj.Fourth_stage, objects=name).to_messages()\n",
        "  env_in_fourth_stage=model(model_request4)\n",
        "\n",
        "\n",
        "  result=f'''The first stage of life cycle of {name} is {obj.first_stage}. In this stage the environment is classified as the following:\\n{env_in_first_stage.content}.\n",
        "  \\n The second stage of life cycle of {name} is {obj.Second_stage}. In this stage the environment is classified as the following:\\n{env_in_second_stage.content}.\n",
        "  \\n The third stage of life cycle of {name} is {obj.Third_stage}. In this stage the environment is classified as the following:\\n{env_in_third_stage.content}.\n",
        "  \\n The fourth stage of life cycle of {name} is {obj.Fourth_stage}. In this stage the environment is classified as the following:\\n{env_in_fourth_stage.content}.\n",
        "  '''\n",
        "  return print(result)"
      ],
      "metadata": {
        "id": "Sdgwjz8EPc_N"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj('chair')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgbiT6DHQBkl",
        "outputId": "2d420bb1-c28d-4e1b-ea5f-5cd0c8fa2c54"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem:  you are an AI assistant that could help designers to understand the lifecycle of chair. You would explain the lifecycle of chair clearly and very breifly in just four stages and provide a  short explanation for every stage \n",
            "Human: I would define lifecycle as events that something passes to reach the point that it is. For instance the lifecycle of an engineer is studying in school, getting good marks, going to colledge, going to university, finding an engineer job. What is life cycle of chair\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "the first stage of life cycle of chair is Design and Production. In this stage the environment is classified as the following:\n",
            "1. In the built environment, the design and production stage of the chair involves the use of materials, tools, and machinery to create the physical form of the chair.\n",
            "2. The human environment in the design and production stage of the chair includes the designers, engineers, and craftsmen who collaborate to bring the chair to life.\n",
            "3. The nature environment plays a role in the design and production stage of the chair through the sourcing of materials, such as wood or metal, which are derived from natural resources.\n",
            "4. The built environment also encompasses the manufacturing facilities and workshops where the chair is designed and produced, providing the necessary infrastructure for the creation process.\n",
            "5. The human environment is further influenced by the skills, expertise, and creativity of the individuals.\n",
            "  \n",
            " the second stage of life cycle of chair is Distribution and Sale. In this stage the environment is classified as the following:\n",
            "1. In the built environment, the chair is displayed and sold in various retail stores and online platforms.\n",
            "2. In the human environment, customers interact with the chair, trying it out and making purchasing decisions based on their preferences and needs.\n",
            "3. In the nature environment, the chair may be affected by factors such as temperature, humidity, and sunlight during transportation and storage..\n",
            "  \n",
            " the third stage of life cycle of chair is Use and Maintenance. In this stage the environment is classified as the following:\n",
            "1. In the built environment, the chair's use and maintenance involve regular cleaning and repairs to ensure its functionality and longevity.\n",
            "2. In the human environment, the chair's use and maintenance depend on the actions and habits of the individuals who interact with it, such as sitting, adjusting, and taking care of it.\n",
            "3. In the nature environment, the chair's use and maintenance may be affected by factors like exposure to sunlight, humidity, and temperature, which can impact its material integrity and overall condition..\n",
            "  \n",
            " the fourth stage of life cycle of chair is Disposal and Recycling. In this stage the environment is classified as the following:\n",
            "1. In the built environment, the chair is made up of various materials such as wood, metal, and plastic, which can be recycled or disposed of properly.\n",
            "2. In the human environment, individuals play a crucial role in ensuring that chairs are recycled or disposed of in an environmentally friendly manner.\n",
            "3. In the natural environment, the recycling or disposal of chairs can help reduce waste and prevent harmful materials from polluting the land, water, and air..\n",
            "  \n"
          ]
        }
      ]
    }
  ]
}